{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6700808e",
   "metadata": {},
   "source": [
    "# Detection of social bots using tweets\n",
    "\n",
    "\n",
    "#### Group 3: Stefani Platakidou, Kinga Jenei, Alejandro Lozada, Liam Le Tran\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5db8b",
   "metadata": {},
   "source": [
    "### Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b38b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\liam\\anaconda3\\envs\\dml\\lib\\site-packages (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af81d05",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cb19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f474f532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6257879",
   "metadata": {},
   "source": [
    "### Data presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f447c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>referenced_tweets_types</th>\n",
       "      <th>referenced_tweets_ids</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>media_types</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bot</td>\n",
       "      <td>t1477711712191090689</td>\n",
       "      <td>2620097396</td>\n",
       "      <td>2022-01-02 18:41:41+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>@Quarry_Rock I had Harris as anytime scorer to...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{840817404}</td>\n",
       "      <td>{}</td>\n",
       "      <td>840817404.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>human</td>\n",
       "      <td>t1493923820893261831</td>\n",
       "      <td>1065878129963646976</td>\n",
       "      <td>2022-02-16 12:22:49+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @forwardfooding: Alex Campos from @Nova_Mea...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{2486723058,1065878129963646976}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>human</td>\n",
       "      <td>t1499799906508173314</td>\n",
       "      <td>32817728</td>\n",
       "      <td>2022-03-04 17:32:17+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>I go into this all in more detail as part of m...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{91478624}</td>\n",
       "      <td>{}</td>\n",
       "      <td>32817728.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bot</td>\n",
       "      <td>t1423386273784467463</td>\n",
       "      <td>37692343</td>\n",
       "      <td>2021-08-05 20:51:47+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @EntheosAi: If we show an AI model millions...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{793303720205230080}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                    id            author_id  \\\n",
       "20    bot  t1477711712191090689           2620097396   \n",
       "21  human  t1493923820893261831  1065878129963646976   \n",
       "22  human  t1499799906508173314             32817728   \n",
       "23    bot  t1423386273784467463             37692343   \n",
       "\n",
       "                   created_at  type  \\\n",
       "20  2022-01-02 18:41:41+00:00  post   \n",
       "21  2022-02-16 12:22:49+00:00  post   \n",
       "22  2022-03-04 17:32:17+00:00  post   \n",
       "23  2021-08-05 20:51:47+00:00  post   \n",
       "\n",
       "                                                 text language geo_location  \\\n",
       "20  @Quarry_Rock I had Harris as anytime scorer to...       en        False   \n",
       "21  RT @forwardfooding: Alex Campos from @Nova_Mea...       en        False   \n",
       "22  I go into this all in more detail as part of m...       en        False   \n",
       "23  RT @EntheosAi: If we show an AI model millions...       en        False   \n",
       "\n",
       "   referenced_tweets_types referenced_tweets_ids  \\\n",
       "20                      {}                    {}   \n",
       "21                      {}                    {}   \n",
       "22                      {}                    {}   \n",
       "23                      {}                    {}   \n",
       "\n",
       "                       user_mentions media_types  in_reply_to_user_id  \\\n",
       "20                       {840817404}          {}          840817404.0   \n",
       "21  {2486723058,1065878129963646976}          {}                  NaN   \n",
       "22                        {91478624}          {}           32817728.0   \n",
       "23              {793303720205230080}          {}                  NaN   \n",
       "\n",
       "   possibly_sensitive  \n",
       "20              False  \n",
       "21              False  \n",
       "22              False  \n",
       "23              False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_sample_nlp.csv\")\n",
    "df.loc[20:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c20ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @EntheosAi: If we show an AI model millions of images and ask it to learn to categorize the world around us, what underlying geometry ofâ€¦'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c8499",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04aa0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Liam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords collection from library\n",
    "nltk.download('stopwords')\n",
    "# Put it into a set to guarantee each word only appear once\n",
    "STOPWORDS = list(set(stopwords.words('english')))\n",
    "# Add punctuation to the stopwords list\n",
    "STOPWORDS+=[\".\", \"!\", \"?\", \",\", \";\", \":\", \"[\", \"]\", \"{\", \"}\", \"-\", \"+\", \n",
    "    \"_\", \"/\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"(\", \")\", \"<\", \">\", \"|\", \"=\",\n",
    "    \".-\", \".,\", \"'\", '\"', ',\"', \".>\", \".<\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a11174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(needs', 'self-determined', 'lâ€™intensification', 'ðŸ’ªðŸ¼ðŸ ðŸŒŠ', 'fuerte,', 'maphitha', 'Ù†Ø§Ø±Ø§Ø­ØªÙ‡', 'conditionâ€¦', 'ÙˆØ§Ù„Ø¥Ø¹Ø¬Ø§Ø¨', 'spacexâ€™s', 'sospeitosos', 'ðŸ¤”Â¿quÃ©', 'websiteðŸ‘‡', 'confiscation', 'ðŸ“ŒempatÃ­a,', 'ruhija', '(pre-fetch,', '(feels', 'destinaremos', 'mwst', 'sounds', 'ðŸ—£massive', 'podiatry', '#chemclass', 'Ø¬Ø±Ø§Øª', '#futureofpinkisgreen!', 'à¤•à¥‰à¤¨à¥à¤«à¥à¤°à¥‡à¤¨à¥à¤¸', 'rosteâ€¦', '#oneusinbeverlyhills', '(48.96%)', 'ã„ã‚ˆã„ã‚ˆé–‹å¹•!æ‰‹æ‹å­ã«æƒ³ã„ã‚’ä¹—ã›ã¦ã€‚ã€‚ã€‚', 'Ø±ÙØªÙ†Ø´ÙˆÙ†', 'Ø¹Ù„ÙŠØ§', '#usacurling', '\"those', 'coresident', 'marr', 'bruce?', '#stargatenow', 'haha,', 'ð‘–ð‘ â€¦', 'llms', 'continent?', 'luna....', 'marash', 'say),', 'referenceâ€', '#solidaritÃ©', 'dices,', 'erruâ€¦', 'analizar', 'à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤ªà¥€à¤ à¤¾à¤¤', 'smultr,age', 'juta', 'caroline,', '#cxp', 'ls4.', 'ÙˆØºØ§Ø²', '#rcotdatastratgy', 'relembrar', 'resources;', 'Ø¨Ù…Ø¬Ø±Ø¯', '#icassp2022', '#cozy', '#pharma', 'bus]', 'universalâ€™s', 'ã‚´ãƒ¼ãƒ«ã¨ã®è·é›¢ã€ãƒ—ãƒ¬ãƒ¼ã®æ–¹å‘ã¯è¦ä»¶ã‚’æº€ãŸã—ã¦ã‚‹ã¨ã¯æ€ãˆãªã„ã‚“ã§ã™ã‘ã©ã­ã€‚', 'awayâ€¦.', 'spiritual,', 'mcconnellâ€™s', 'ai/pixel', 'Ù…ÛŒØ²Ù†Ù†!!!', 'crates', 'escenas,', 'nordics', 'kans?', '#yourlocalguilâ€¦', 'daydreaming.', '#actingtwt', 'ora,', 'ncbi-nr', 'à¤­à¤¨à¥‡', 'congratulations!!!ðŸ¥‚', 'braveâ€¦', '4.07%,', 'mandateâ€™:', 'ï¼ŠéŸ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚', '#presidenttrump', 'bulbs,', 'nouveâ€¦', 'shout-out.', '#allaboard!!', 'compaÃ±eras...', 'gesperrt.', '#wheelchairlife', '#ats', 'hijacking,', '#roastdinner', '6pmðŸ‘‡']\n",
      "\n",
      "Total unique words in all tweets: 609566\n",
      "\n",
      "['(needs', 'self-determined', 'lâ€™intensification', 'fuerte,', 'maphitha', 'Ù†Ø§Ø±Ø§Ø­ØªÙ‡', 'conditionâ€¦', 'ÙˆØ§Ù„Ø¥Ø¹Ø¬Ø§Ø¨', 'spacexâ€™s', 'sospeitosos', 'confiscation', 'ruhija', '(pre-fetch,', '(feels', 'destinaremos', 'mwst', 'sounds', 'podiatry', '#chemclass', 'Ø¬Ø±Ø§Øª', '#futureofpinkisgreen!', 'à¤•à¥‰à¤¨à¥à¤«à¥à¤°à¥‡à¤¨à¥à¤¸', 'rosteâ€¦', '#oneusinbeverlyhills', '(48.96%)', 'ã„ã‚ˆã„ã‚ˆé–‹å¹•!æ‰‹æ‹å­ã«æƒ³ã„ã‚’ä¹—ã›ã¦ã€‚ã€‚ã€‚', 'Ø±ÙØªÙ†Ø´ÙˆÙ†', 'Ø¹Ù„ÙŠØ§', '#usacurling', '\"those', 'coresident', 'marr', 'bruce?', '#stargatenow', 'haha,', 'ð‘–ð‘ â€¦', 'llms', 'continent?', 'luna....', 'marash', 'say),', 'referenceâ€', '#solidaritÃ©', 'dices,', 'erruâ€¦', 'analizar', 'à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤ªà¥€à¤ à¤¾à¤¤', 'smultr,age', 'juta', 'caroline,', '#cxp', 'ls4.', 'ÙˆØºØ§Ø²', '#rcotdatastratgy', 'relembrar', 'resources;', 'Ø¨Ù…Ø¬Ø±Ø¯', '#icassp2022', '#cozy', '#pharma', 'bus]', 'universalâ€™s', 'ã‚´ãƒ¼ãƒ«ã¨ã®è·é›¢ã€ãƒ—ãƒ¬ãƒ¼ã®æ–¹å‘ã¯è¦ä»¶ã‚’æº€ãŸã—ã¦ã‚‹ã¨ã¯æ€ãˆãªã„ã‚“ã§ã™ã‘ã©ã­ã€‚', 'awayâ€¦.', 'spiritual,', 'mcconnellâ€™s', 'ai/pixel', 'Ù…ÛŒØ²Ù†Ù†!!!', 'crates', 'escenas,', 'nordics', 'kans?', '#yourlocalguilâ€¦', 'daydreaming.', '#actingtwt', 'ora,', 'ncbi-nr', 'à¤­à¤¨à¥‡', 'braveâ€¦', '4.07%,', 'mandateâ€™:', 'ï¼ŠéŸ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚', '#presidenttrump', 'bulbs,', 'nouveâ€¦', 'shout-out.', '#allaboard!!', 'compaÃ±eras...', 'gesperrt.', '#wheelchairlife', '#ats', 'hijacking,', '#roastdinner', 'sponsoring.', 'paddock', 'jodas', '#sk8ernez', '18f-fluciclovine', '#à¤œà¤¯_à¤•à¤¿à¤¸à¤¾à¤¨', 'gringa']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Questions : \n",
    "1. In general, what are the characteristics of a text written by a social bot?\n",
    "2. Do they not contain tagged accounts? \n",
    "3. How do we handle emojis? Do they indicate that an account is a bot?\n",
    "4. How do we handle other languages?\n",
    "\n",
    "Notes: \n",
    "The number of unique words are still too high?\n",
    "Very slow when remove emojies\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\"\"\"\n",
    "    #remove all languages except english\n",
    "  \n",
    "    \n",
    "    # update tweets by lowercase, strip and tokenize\n",
    "    unique_word_freqs = set()\n",
    "    df['text'].str.lower().str.split().apply(unique_word_freqs.update)\n",
    "\n",
    "    # exclude stop words, tagged accounts, punctuation, links and numbers    \n",
    "    unique_word_freqs = list(unique_word_freqs)\n",
    "    data = [word for i,word in enumerate(unique_word_freqs) if ( '@' not in word) and ('http' not in word) \\\n",
    "            and (word not in STOPWORDS) and (not word.isnumeric())]\n",
    "    print(data[:100])\n",
    "    \n",
    "    # remove emojies\n",
    "    clean_text = \" \".join([word for word in data if not any(i in word for i in emoji.EMOJI_DATA)]).split()\n",
    "    \n",
    "    print(f'\\nTotal unique words in all tweets: {len(clean_text)}\\n')   \n",
    "    return clean_text\n",
    "    \n",
    "data = preprocess(df)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53a10a",
   "metadata": {},
   "source": [
    "### Rep zng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c7c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3591b0ce",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e426f78",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988c4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
