{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8510a7",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547886b",
   "metadata": {},
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12817854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line if you run the notebook for the first time\n",
    "\n",
    "#%pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a731a70",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adac86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore print warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccee299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d58cd2",
   "metadata": {},
   "source": [
    "### Data presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd518778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>referenced_tweets_types</th>\n",
       "      <th>referenced_tweets_ids</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>media_types</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>human</td>\n",
       "      <td>t1471504881882075140</td>\n",
       "      <td>17268418</td>\n",
       "      <td>2021-12-16 15:37:57+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @ElemPE1: \"Toys for Tots\"üéÅ\\n\\nLess lecturin...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{907432611319914497}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300000</th>\n",
       "      <td>human</td>\n",
       "      <td>t1499064851347304449</td>\n",
       "      <td>33152005</td>\n",
       "      <td>2022-03-02 16:51:26+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>@DavidVimes Same.</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{966462024145391616}</td>\n",
       "      <td>{}</td>\n",
       "      <td>9.664620e+17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300001</th>\n",
       "      <td>human</td>\n",
       "      <td>t1492208040795324425</td>\n",
       "      <td>76086369</td>\n",
       "      <td>2022-02-11 18:44:55+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>@BigelowLab I spy a @wellsreserve alumna!</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{260908660,76086369}</td>\n",
       "      <td>{}</td>\n",
       "      <td>2.609087e+08</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300002</th>\n",
       "      <td>human</td>\n",
       "      <td>t942173606888595457</td>\n",
       "      <td>709501413819293696</td>\n",
       "      <td>2017-12-16 23:24:27+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @MPSHaringey: Who thinks #PDBoots deserves ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{407149465}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300003</th>\n",
       "      <td>human</td>\n",
       "      <td>t1498058873269370880</td>\n",
       "      <td>2218413296</td>\n",
       "      <td>2022-02-27 22:14:02+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>1 BTC = 37,535 USD</td>\n",
       "      <td>vi</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                    id           author_id  \\\n",
       "299999  human  t1471504881882075140            17268418   \n",
       "300000  human  t1499064851347304449            33152005   \n",
       "300001  human  t1492208040795324425            76086369   \n",
       "300002  human   t942173606888595457  709501413819293696   \n",
       "300003  human  t1498058873269370880          2218413296   \n",
       "\n",
       "                       created_at  type  \\\n",
       "299999  2021-12-16 15:37:57+00:00  post   \n",
       "300000  2022-03-02 16:51:26+00:00  post   \n",
       "300001  2022-02-11 18:44:55+00:00  post   \n",
       "300002  2017-12-16 23:24:27+00:00  post   \n",
       "300003  2022-02-27 22:14:02+00:00  post   \n",
       "\n",
       "                                                     text language  \\\n",
       "299999  RT @ElemPE1: \"Toys for Tots\"üéÅ\\n\\nLess lecturin...       en   \n",
       "300000                                  @DavidVimes Same.       en   \n",
       "300001          @BigelowLab I spy a @wellsreserve alumna!       en   \n",
       "300002  RT @MPSHaringey: Who thinks #PDBoots deserves ...       en   \n",
       "300003                                 1 BTC = 37,535 USD       vi   \n",
       "\n",
       "       geo_location referenced_tweets_types referenced_tweets_ids  \\\n",
       "299999        False                      {}                    {}   \n",
       "300000        False                      {}                    {}   \n",
       "300001        False                      {}                    {}   \n",
       "300002        False                      {}                    {}   \n",
       "300003        False                      {}                    {}   \n",
       "\n",
       "               user_mentions media_types  in_reply_to_user_id  \\\n",
       "299999  {907432611319914497}          {}                  NaN   \n",
       "300000  {966462024145391616}          {}         9.664620e+17   \n",
       "300001  {260908660,76086369}          {}         2.609087e+08   \n",
       "300002           {407149465}          {}                  NaN   \n",
       "300003                    {}          {}                  NaN   \n",
       "\n",
       "       possibly_sensitive  \n",
       "299999              False  \n",
       "300000              False  \n",
       "300001              False  \n",
       "300002              False  \n",
       "300003              False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_sample_nlp.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa23572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @EntheosAi: If we show an AI model millions of images and ask it to learn to categorize the world around us, what underlying geometry of‚Ä¶'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c8a38",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac350a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>referenced_tweets_types</th>\n",
       "      <th>referenced_tweets_ids</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>media_types</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bot</td>\n",
       "      <td>t1477711712191090689</td>\n",
       "      <td>2620097396</td>\n",
       "      <td>2022-01-02 18:41:41+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>@Quarry_Rock I had Harris as anytime scorer to...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{840817404}</td>\n",
       "      <td>{}</td>\n",
       "      <td>840817404.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>human</td>\n",
       "      <td>t1493923820893261831</td>\n",
       "      <td>1065878129963646976</td>\n",
       "      <td>2022-02-16 12:22:49+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @forwardfooding: Alex Campos from @Nova_Mea...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{2486723058,1065878129963646976}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>human</td>\n",
       "      <td>t1499799906508173314</td>\n",
       "      <td>32817728</td>\n",
       "      <td>2022-03-04 17:32:17+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>I go into this all in more detail as part of m...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{91478624}</td>\n",
       "      <td>{}</td>\n",
       "      <td>32817728.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bot</td>\n",
       "      <td>t1423386273784467463</td>\n",
       "      <td>37692343</td>\n",
       "      <td>2021-08-05 20:51:47+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>RT @EntheosAi: If we show an AI model millions...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{793303720205230080}</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>human</td>\n",
       "      <td>t1499430143441440769</td>\n",
       "      <td>31373289</td>\n",
       "      <td>2022-03-03 17:02:58+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>Thanks to the Scottish Rugby Union and other E...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{photo}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>human</td>\n",
       "      <td>t1478759851337519108</td>\n",
       "      <td>839166270289362946</td>\n",
       "      <td>2022-01-05 16:06:37+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>Did a really rad in-class project today with @...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{1018830203768967170}</td>\n",
       "      <td>{photo}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>human</td>\n",
       "      <td>t1499112813859688461</td>\n",
       "      <td>278206598</td>\n",
       "      <td>2022-03-02 20:02:01+00:00</td>\n",
       "      <td>post</td>\n",
       "      <td>üì£ Attn #LincolnON - the Town is undergoing a w...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{photo}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                    id            author_id  \\\n",
       "20    bot  t1477711712191090689           2620097396   \n",
       "21  human  t1493923820893261831  1065878129963646976   \n",
       "22  human  t1499799906508173314             32817728   \n",
       "23    bot  t1423386273784467463             37692343   \n",
       "24  human  t1499430143441440769             31373289   \n",
       "26  human  t1478759851337519108   839166270289362946   \n",
       "28  human  t1499112813859688461            278206598   \n",
       "\n",
       "                   created_at  type  \\\n",
       "20  2022-01-02 18:41:41+00:00  post   \n",
       "21  2022-02-16 12:22:49+00:00  post   \n",
       "22  2022-03-04 17:32:17+00:00  post   \n",
       "23  2021-08-05 20:51:47+00:00  post   \n",
       "24  2022-03-03 17:02:58+00:00  post   \n",
       "26  2022-01-05 16:06:37+00:00  post   \n",
       "28  2022-03-02 20:02:01+00:00  post   \n",
       "\n",
       "                                                 text language geo_location  \\\n",
       "20  @Quarry_Rock I had Harris as anytime scorer to...       en        False   \n",
       "21  RT @forwardfooding: Alex Campos from @Nova_Mea...       en        False   \n",
       "22  I go into this all in more detail as part of m...       en        False   \n",
       "23  RT @EntheosAi: If we show an AI model millions...       en        False   \n",
       "24  Thanks to the Scottish Rugby Union and other E...       en        False   \n",
       "26  Did a really rad in-class project today with @...       en        False   \n",
       "28  üì£ Attn #LincolnON - the Town is undergoing a w...       en        False   \n",
       "\n",
       "   referenced_tweets_types referenced_tweets_ids  \\\n",
       "20                      {}                    {}   \n",
       "21                      {}                    {}   \n",
       "22                      {}                    {}   \n",
       "23                      {}                    {}   \n",
       "24                      {}                    {}   \n",
       "26                      {}                    {}   \n",
       "28                      {}                    {}   \n",
       "\n",
       "                       user_mentions media_types  in_reply_to_user_id  \\\n",
       "20                       {840817404}          {}          840817404.0   \n",
       "21  {2486723058,1065878129963646976}          {}                  NaN   \n",
       "22                        {91478624}          {}           32817728.0   \n",
       "23              {793303720205230080}          {}                  NaN   \n",
       "24                                {}     {photo}                  NaN   \n",
       "26             {1018830203768967170}     {photo}                  NaN   \n",
       "28                                {}     {photo}                  NaN   \n",
       "\n",
       "   possibly_sensitive  \n",
       "20              False  \n",
       "21              False  \n",
       "22              False  \n",
       "23              False  \n",
       "24              False  \n",
       "26              False  \n",
       "28              False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out tweets that aren't english\n",
    "df = df.loc[df[\"language\"] == \"en\"]\n",
    "df.loc[20:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd04f514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human    202760\n",
       "bot       17392\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts() # unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "533d7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kingu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# # Download the stopwords collection from library\n",
    "nltk.download('stopwords')\n",
    "# Put it into a set to guarantee each word only appear once\n",
    "STOPWORDS = list(set(stopwords.words('english')))\n",
    "# Add punctuation to the stopwords list\n",
    "STOPWORDS += [\".\", \"!\", \"?\", \",\", \";\", \":\", \"[\", \"]\", \"{\", \"}\", \"-\", \"+\", \n",
    "    \"_\", \"/\", \"#\", \"@\", \"$\", \"%\", \"^\", \"&\", \"*\", \"(\", \")\", \"<\", \">\", \"|\", \"=\",\n",
    "    \".-\", \".,\", \"'\", '\"', ',\"', \".>\", \".<\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07a026df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    RT @Wieneraaron: When you need your emotional ...\n",
       "3    RT @InfoSecSherpa: \"The Thurgood Marshall Coll...\n",
       "4    RT @NCIAorg: BREAKING ‚Äì¬†SAFE Banking Act Reint...\n",
       "5           @L1nds Oooh I like https://t.co/Y5V50GCHdB\n",
       "8          No war!.....PLEASE! https://t.co/YGxOZpN5Kk\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe773f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, lowercase=False, stopwords=False, links=False, tags=False, numbers=False, emojis=False, hashtag=False,\n",
    "                 rt=False):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "    text = new_df['text']\n",
    "    \n",
    "    # lowercasing everything\n",
    "    if lowercase:\n",
    "        text = text.apply(lambda x: str.lower(x))\n",
    "    \n",
    "    # removing stopword\n",
    "    if stopwords:\n",
    "        # we have to look at the lowercase words, since the stopwords are lowercase\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if str.lower(word) not in STOPWORDS]))\n",
    "    \n",
    "    # removing links\n",
    "    if links:\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if 'http' not in word]))\n",
    "    \n",
    "    # removing tags\n",
    "    if tags:\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if '@' not in word]))\n",
    "    \n",
    "    # removing numbers only if the whole word is numeric - eg. we remove 1123 but not 1123a\n",
    "    if numbers:\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if not word.isnumeric()]))\n",
    "    \n",
    "    # removing emojis (whole word if it contains an emoji)\n",
    "    if emojis:\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if not any(i in word for i in emoji.EMOJI_DATA)]))\n",
    "    \n",
    "    # removing hashtags\n",
    "    if hashtag:\n",
    "        text = text.apply(lambda x: \" \".join([word for word in x.split() if '#' not in word]))\n",
    "        \n",
    "    # removing rt from the beginning\n",
    "    if rt:\n",
    "        text = text.apply(lambda x: \" \".join([word for i,word in enumerate(x.split()) if not (i==0 and str.lower(word)=='rt')]))\n",
    "    \n",
    "    new_df['text'] = text\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df0f5c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                      need emotional support chicken.\n",
       "3    \"The Thurgood Marshall College Fund (TMCF), Pa...\n",
       "4    BREAKING ‚Äì SAFE Banking Act Reintroduced House...\n",
       "5                                            Oooh like\n",
       "8                                     war!.....PLEASE!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed=preprocessing(df.head(), lowercase=False, stopwords=True, links=True, tags=True, numbers=True, \n",
    "              emojis=True, hashtag=True, rt=True)\n",
    "df_preprocessed['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d324e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a03496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#sharpiegate', 'poland.‚Ä¶', '#healthinsurance.‚Äù', '#aievents', '#0339', '8-12,', '#tedtalks', 'fastmri.', 'minute-by-minute,', 'mencken', 'chills', '#tips', 'newsblocks', 't&amp;k', 'mobiles', '#thelastofuspart2', '#breakfastlover', 'nova?', '#authorsrock', 'implications.', 'suici‚Ä¶', '\"3x', '#cseiiitd', 'changer.', 'stinger', 'brother#your', 'tamale,', '4(b)', 'kibale', 'bus/lirr/bike/walk/other', '#smallbusinessowner', 'globe.', 'spins!', '#shetland', 'server,', 'tuhina', '‚¨ú‚¨ú‚¨ú‚¨úüü©', 'alleviate.', 'hamiltonian.', '#chayat', 'informative', 'emotion', 'hush', 'spectacle', 'unexplainable', '#nse', '#ool2020', '#worldtravelerer', '#clicklessanalytics4comparison', 'andy', 'nada', 'cecil', 'cvcs', 'fyi', 'lbp/usd.', 'retransitioned', '(aaveusdt)', 'hackney', '#freejazzz', '#gilford', 'narowal', 'üò±üò±üò±üò±', 'online-only', '#machinery', '#instagamer', 'atos', 'hoagie', 'insulins', 'ompc/f', 'farsi', '#consumerprivacy', 'announcement....', 'source)', 'carbene', 'bex!!!', 'üá¨üáß:', 'krita', 'felons', 'reductress', 'jmalvpal:', 'bcl', 'cny.', 'silky', 'enhancements.', 'nanyuki', '~2016', 'aran', '‚õîÔ∏è‚ÄºÔ∏èüî¥]', \"byfield's\", 'essence!', 'kenna', 'anti-vax,', 'grant‚Äîand', 'gathering', '#fusible', 'tarzana', 'incubator', 'abdulaev', 'somatic', 'dasgupta‚Äôs']\n",
      "\n",
      "Total unique words in all tweets: 336907\n",
      "\n",
      "['sharpiegate', 'poland', 'healthinsurance', 'aievents', '0339', '812', 'tedtalks', 'fastmri', 'minutebyminute', 'mencken', 'chills', 'tips', 'newsblocks', 'tampk', 'mobiles', 'thelastofuspart2', 'breakfastlover', 'nova', 'authorsrock', 'implications', 'suici', '3x', 'cseiiitd', 'changer', 'stinger', 'brotheryour', 'tamale', '4b', 'kibale', 'buslirrbikewalkother', 'smallbusinessowner', 'globe', 'spins', 'shetland', 'server', 'tuhina', 'alleviate', 'hamiltonian', 'chayat', 'informative', 'emotion', 'hush', 'spectacle', 'unexplainable', 'nse', 'ool2020', 'worldtravelerer', 'clicklessanalytics4comparison', 'andy', 'nada', 'cecil', 'cvcs', 'fyi', 'lbpusd', 'retransitioned', 'aaveusdt', 'hackney', 'freejazzz', 'gilford', 'narowal', 'onlineonly', 'machinery', 'instagamer', 'atos', 'hoagie', 'insulins', 'ompcf', 'farsi', 'consumerprivacy', 'announcement', 'source', 'carbene', 'bex', 'krita', 'felons', 'reductress', 'jmalvpal', 'bcl', 'cny', 'silky', 'enhancements', 'nanyuki', '2016', 'aran', 'byfields', 'essence', 'kenna', 'antivax', 'grantand', 'gathering', 'fusible', 'tarzana', 'incubator', 'abdulaev', 'somatic', 'dasguptas', 'marlboro', '36days_c', 'conncoll', 'anticas']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Questions : \n",
    "1. In general, what are the characteristics of a text written by a social bot?\n",
    "2. Do they not contain account tags? \n",
    "3. How do we handle emojies? Do they indicate that an account is a bot?\n",
    "4. Do we only stick to English?\n",
    "\n",
    "Notes: \n",
    "The number of unique words are still too high?\n",
    "Very slow when remove emojies\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    This function takes a dataframe with different features \n",
    "    and returns pre-processed texts from the tweets \n",
    "    \"\"\"\n",
    "\n",
    "    # update tweets by lowercase, strip and tokenize\n",
    "    unique_word_freqs = set()\n",
    "    df['text'].str.lower().str.split().apply(unique_word_freqs.update)\n",
    "\n",
    "    # exclude stop words, tagged accounts, punctuation, links and numbers    \n",
    "    unique_word_freqs = list(unique_word_freqs)\n",
    "    data = [word for i,word in enumerate(unique_word_freqs) if ( '@' not in word) and ('http' not in word) \\\n",
    "            and (word not in STOPWORDS) and (not word.isnumeric())]\n",
    "    print(data[:100])\n",
    "    \n",
    "    # remove emojies\n",
    "    clean_text = \" \".join([word for word in data if not any(i in word for i in emoji.EMOJI_DATA)])\n",
    "    \n",
    "    #remove punctuation inside of words\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text).split()\n",
    "\n",
    "    \n",
    "    print(f'\\nTotal unique words in all tweets: {len(clean_text)}\\n')   \n",
    "    return clean_text\n",
    "    \n",
    "data = preprocess(df)\n",
    "print(data[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "917465e231de0303214f3286e28ee0d1023542557ef1c3f474efb076deb95ba9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
